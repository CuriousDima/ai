{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5a10c5-3041-4350-9492-4f69fcd3b83f",
   "metadata": {},
   "source": [
    "# Text to Embedding with ModernBERT\n",
    "\n",
    "ModernBERT: \"Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference\" https://arxiv.org/abs/2412.13663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b6c959-492d-469a-bd69-862deaf0eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0cbc67-48fa-49dc-91ee-40a63538dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bc59d0-8cf0-4574-aa48-30bbc33cab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"It's such a pleasure to see you, my friend!\",\n",
    "    \"I'm so happy to see you, buddy!\",\n",
    "    \"Great to see you again, pal!\",\n",
    "    \"This includes setting up effective monitoring and alerting systems.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd08d86-b692-46e6-8972-aafed7a001a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "encoded_input = tokenizer(\n",
    "    texts,\n",
    "    padding=True,  # ensures that all sequences are padded to the same length.\n",
    "    return_tensors='pt'  # return PyTorch tensors. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97b8e9f-cfd4-4ef9-b979-f677642ce878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281,  1147,   434,   824,   247, 11284,   281,   923,   368,    13,\n",
       "           619,  3331,     2, 50282],\n",
       "        [50281,    42,  1353,   594,  5211,   281,   923,   368,    13, 29517,\n",
       "             2, 50282, 50283, 50283],\n",
       "        [50281, 15611,   281,   923,   368,   969,    13,  5796,     2, 50282,\n",
       "         50283, 50283, 50283, 50283],\n",
       "        [50281,  1552,  3797,  4758,   598,  3576,  8667,   285, 10028,   272,\n",
       "          2718,    15, 50282, 50283]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16ea9e9-dc9f-4b12-a2df-b90deaf96a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the tokenized inputs through the model to obtain the embeddings.\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bec2f85-9787-4a8b-bc35-aba0204f969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The [CLS] token embedding is the first token's embedding\n",
    "cls_embeddings = model_output.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492351fc-82a1-4d21-aa64-2808265a973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28d0929-42f8-4f39-b149-e1f4306cd37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'It's such a pleasure to see you, my friend!'\n",
      " and 'I'm so happy to see you, buddy!'\n",
      " similarity: tensor([0.9883])\n",
      "\n",
      "'It's such a pleasure to see you, my friend!'\n",
      " and 'Great to see you again, pal!'\n",
      " similarity: tensor([0.9861])\n",
      "\n",
      "'It's such a pleasure to see you, my friend!'\n",
      " and 'This includes setting up effective monitoring and alerting systems.'\n",
      " similarity: tensor([0.9139])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"'{texts[0]}'\\n and '{texts[1]}'\\n similarity: %s\\n\" % F.cosine_similarity(cls_embeddings[0].unsqueeze(0), cls_embeddings[1].unsqueeze(0)))\n",
    "print(f\"'{texts[0]}'\\n and '{texts[2]}'\\n similarity: %s\\n\" % F.cosine_similarity(cls_embeddings[0].unsqueeze(0), cls_embeddings[2].unsqueeze(0)))\n",
    "print(f\"'{texts[0]}'\\n and '{texts[3]}'\\n similarity: %s\\n\" % F.cosine_similarity(cls_embeddings[0].unsqueeze(0), cls_embeddings[3].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9054bf0-269c-4f8a-9117-aecff6e1fc01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
